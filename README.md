# Мои работы по машинному обучению


Коротко: домашние работы, где я прохожу путь **данные → EDA → фичи → модель → валидация → выводы** на реальных датасетах.  
EDA — разведочный анализ, **фичи** — признаки (подготовленные столбцы для модели), **валидация** — честная проверка качества на отложенных данных.

## Проекты

- **1_Pandas — обработка табличных данных (учебный набор «студенты»).**  
  Сбор единого датафрейма из разрозненных CSV (инфо + оценки по 10 группам), `merge/concat`, агрегирование `groupby`, сводные таблицы.  
  **Зачем:** базовые приёмы подготовки данных перед моделированием.

- **2_SklearnLinearModels — регрессия цен на бриллианты (Kaggle: *Diamonds*, ~54k строк).**  
  Предсказываю `price` по признакам `carat`, `cut`, `color`, `clarity` и размерам. One-Hot кодирование категорий, масштабирование, регуляризация (Ridge/Lasso). Метрики: **MSE/RMSE/R²**.  
  **Где применяется:** ценообразование, оценка стоимости.

- **3_feature — фичи + подбор моделей (scikit-learn: *Diabetes*).**  
  Цель — предсказать показатель прогрессии заболевания через год. Сравнение **LinearRegression** и **DecisionTreeRegressor**, полиномиальные признаки, `Pipeline`, `GridSearchCV`.  
  **Смысл:** показать влияние инженерии признаков и подбора гиперпараметров на качество.

- **4_SVM-LogReg — классификация дохода.**  
  Бинарная задача: `>50k`/`<=50k`. Модели: **Logistic Regression** и **SVM**, кросс-валидация, метрики **Accuracy/F1/ROC-AUC**.  
  **Где применяется:** скоринг и отбор кандидатов по анкетным данным.

- **5_clustering — кластеризация музыкальных предпочтений (матрица «пользователь × исполнитель»).**  
  K-Means по долям прослушивания, интерпретация кластеров (жанровые профили).  
  **Зачем:** сегментация аудитории для рекомендаций.


**Данные:** данные лежат в папках проектов или имеют ссылку в ноутбуке; ссылки и инструкции — внутри папок проектов.  
**Стек:** Python, pandas, numpy, sklearn, matplotlib.

